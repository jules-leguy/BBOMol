{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from os import makedirs\n",
    "\n",
    "# Evolutionary experiment path\n",
    "evomol_exp_dict = {\n",
    "    \"Evolutionary optimization only\" : \"output/01_EA_baseline\" \n",
    "}\n",
    "\n",
    "# BBO experiments paths\n",
    "BBO_exp_dict = {\n",
    "    \"BBO(Shingles, Â·)\": \"output/03_BBO_SHINGLES_DP\",\n",
    "    \"BBO(MBTR, RBF)\": \"output/02_BBO_MBTR_RBF\"\n",
    "}\n",
    "\n",
    "# Names of the different runs (runs that are not defined will be ignored)\n",
    "sub_experiments_names = [str(i) for i in range(10)]\n",
    "\n",
    "# Output destination of figures\n",
    "output_figures_path = \"output/04_figures\"\n",
    "makedirs(output_figures_path, exist_ok=True)\n",
    "\n",
    "# Numerical targets for ECDF representation and ERT measure\n",
    "ECDF_TARGETS = np.arange(-10, -1, 0.01)\n",
    "ERT_TARGETS = np.arange(-10, -1, 1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "sub_experiments_names = [\"0\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bbomol.postprocessing import extract_multiple_BBO_experiments_data, extract_multiple_evomol_experiments_data\n",
    "\n",
    "def extract_all_data(BBO_experiments_dict, EvoMol_experiments_dict, sub_experiments_names):\n",
    "    \n",
    "    results_dict = {}\n",
    "    \n",
    "    for exp_name, path in BBO_experiments_dict.items():\n",
    "        results_dict[exp_name] = extract_multiple_BBO_experiments_data(path, sub_experiments_names)\n",
    "        \n",
    "    for exp_name, path in EvoMol_experiments_dict.items():\n",
    "        results_dict[exp_name] = extract_multiple_evomol_experiments_data(path, sub_experiments_names)\n",
    "\n",
    "    return results_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting all results\n",
    "results_dict = extract_all_data(BBO_exp_dict, evomol_exp_dict, sub_experiments_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Empirical cumulative distribution functions (ECDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set(style=\"ticks\", color_codes=True)\n",
    "from bbomol.evaluation import compute_ecdf, compute_timestamps_ecdf\n",
    "from os.path import join\n",
    "\n",
    "def plot_ECDF(results_dict, timestamps=False):\n",
    "        \n",
    "    plt.figure(figsize=(7, 5))\n",
    "\n",
    "    for i, experiment_name in enumerate(list(results_dict.keys())):\n",
    "        \n",
    "        if timestamps:\n",
    "            obj_calls, ecdf_vect = compute_timestamps_ecdf(\n",
    "                timestamps_list=results_dict[experiment_name][\"timestamps\"],\n",
    "                obj_values_list=results_dict[experiment_name][\"best_scores_timestamps\"],\n",
    "                targets=ECDF_TARGETS\n",
    "            )\n",
    "            \n",
    "            plt.plot(obj_calls/3600, ecdf_vect, label=experiment_name)\n",
    "            \n",
    "        else:\n",
    "            obj_calls, ecdf_vect = compute_ecdf(\n",
    "                    obj_calls_list=results_dict[experiment_name][\"dataset_success_n_calls\"],\n",
    "                    obj_values_list=results_dict[experiment_name][\"dataset_success_obj_value\"],\n",
    "                    targets=ECDF_TARGETS\n",
    "            )\n",
    "            \n",
    "            plt.plot(obj_calls, ecdf_vect, label=experiment_name)\n",
    "\n",
    "        \n",
    "    if timestamps:\n",
    "        plt.xlim(0, 60)\n",
    "        plt.xlabel(\"Time (h)\")\n",
    "    else:\n",
    "        plt.xlim(1, 1000)\n",
    "        plt.xlabel(\"# DFT calls\")\n",
    "    \n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.ylim(0, 1)\n",
    "    plt.ylabel(\"Proportion of targets achieved\")\n",
    "\n",
    "    plt.savefig(join(output_figures_path, \"ECDF.png\"), dpi=600)\n",
    "    plt.show()\n",
    "    \n",
    "def plot_ECDF_timestamps(results_dict):\n",
    "        \n",
    "    plt.figure(figsize=(7, 5))\n",
    "\n",
    "    for i, experiment_name in enumerate(list(results_dict.keys())):\n",
    "        \n",
    "        \n",
    "\n",
    "        plt.plot(obj_calls, ecdf_vect, label=experiment_name)\n",
    "    \n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.xlim(1, 1000)\n",
    "    plt.ylim(0, 1)\n",
    "    plt.xlabel(\"# DFT calls\")\n",
    "    plt.ylabel(\"Proportion of targets achieved\")\n",
    "\n",
    "    plt.savefig(join(output_figures_path, \"ECDF.png\"), dpi=600)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_ECDF(results_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_ECDF(results_dict, timestamps=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Expected running time (ERT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bbomol.evaluation import compute_ERT, compute_ERT_timestamps\n",
    "from IPython.display import display, HTML\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def display_ERT(results_dict, timestamps=False):\n",
    "    \n",
    "    output_keys = [\"Experiment\"] + [str(value) for value in ERT_TARGETS]\n",
    "    ERT_dict = {output_key: [] for output_key in output_keys}\n",
    "    \n",
    "    if timestamps:\n",
    "        display(HTML(\"<h3> Time (h) </h3>\"))\n",
    "    else:\n",
    "        display(HTML(\"<h3> Number of DFT calls </h3>\"))\n",
    "\n",
    "    for i, experiment_name in enumerate(list(results_dict.keys())):\n",
    "        \n",
    "        if timestamps:\n",
    "            \n",
    "            ERT_vect = compute_ERT_timestamps(\n",
    "                timestamps_list=results_dict[experiment_name][\"timestamps\"],\n",
    "                obj_values_list=results_dict[experiment_name][\"best_scores_timestamps\"],\n",
    "                targets=ERT_TARGETS,\n",
    "                effective_last_timestamp_list=results_dict[experiment_name][\"effective_last_timestamp\"]\n",
    "            )/3600\n",
    "            \n",
    "        else:\n",
    "        \n",
    "            ERT_vect = compute_ERT(\n",
    "                obj_calls_list=results_dict[experiment_name][\"dataset_success_n_calls\"],\n",
    "                obj_values_list=results_dict[experiment_name][\"dataset_success_obj_value\"],\n",
    "                targets=ERT_TARGETS\n",
    "            )\n",
    "        \n",
    "        ERT_dict[\"Experiment\"].append(experiment_name)\n",
    "        \n",
    "        for j in range(len(ERT_vect)):\n",
    "            ERT_dict[output_keys[j+1]].append(ERT_vect[j])\n",
    "    \n",
    "    df = pd.DataFrame.from_dict(ERT_dict)\n",
    "    display(df)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_ERT(results_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_ERT(results_dict, timestamps=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
